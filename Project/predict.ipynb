{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle as rick\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [],
   "source": [
    "# read and prepare models\n",
    "content_model_pickle = rick.load(open('content_model.pkl', 'rb'))\n",
    "content_model = content_model_pickle['model']\n",
    "imputer = content_model_pickle['imputer']\n",
    "\n",
    "collabrative_model_pickle = rick.load(open('collaborative_model.pkl', 'rb'))\n",
    "similarity_matrix = pd.DataFrame(collabrative_model_pickle['cosine_similarity'])\n",
    "ratings_matrix = collabrative_model_pickle['ratings_matrix']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction design\n",
    "\n",
    "I have decided that the most suitable type for predicting rating is a hybrid version between content-based and collaborative filtering.\n",
    "Since we have many ratings i can use collaborative filtering item-to-item which is the method that works best in practice.\n",
    "Only for the users that have rated few movies a content based approach would make sense.\n",
    "The regression for my content-based model usually have an RMSE of about 1, which means that if the rating is 4, it predicts either 4, or there is a chance that the model predicts 3 or 5.\n",
    "I will use the I will use the content-based approach on the users with the lowest number of rankings.\n",
    "Below is a table which displays the number of rankings for a user in the lowest percentiles.\n",
    "I will choose where to transition from a collaborative filtering model to a content-based based on these numbers\n",
    "\n",
    "|Percentile |Number of ratings |\n",
    "|----------- |------------------ |\n",
    "|5 |21 |\n",
    "|10 |25 |\n",
    "|15 |29 |\n",
    "|20 |34 |\n",
    "|30 | 46 |\n",
    "\n",
    "I am going to use the conten-based prediction on users with the lowest 15% of ratings, and the collabrative filtering on the 85% rest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [],
   "source": [
    "# Indexes and movies id are not equal, so i make two functions to help converting\n",
    "to_index = {}\n",
    "to_id = {}\n",
    "\n",
    "for i,e in enumerate(ratings_matrix[0].index.tolist()):\n",
    "    to_index[e] = i\n",
    "    to_id[i] = e\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "#Colaborative recommender model\n",
    "\n",
    "\n",
    "def collabrative_user_movie(user_id,movie_id,rows,N):\n",
    "\n",
    "    \"\"\"Collaborative filter prediction for a given user and movie\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int) : UserID\n",
    "    N (int) : Number of most correlated movies to use when predicting ranking for unknown data points\n",
    "    Returns: Number of ratings made by a user (used for content-based/collaborative hybrid) and predicted ratings for all movies not rated by given user\n",
    "    (int,[(int,[int])): (Number of ratings by user,[(movie_id, predicted rating)\n",
    "\n",
    "   \"\"\"\n",
    "    movie_index=to_index[movie_id]\n",
    "    movie_row = rows.iloc[:,movie_index].sort_values(ascending=False)\n",
    "    most_similar_corr = movie_row.values[:N]\n",
    "    most_similar_indexes = movie_row.index.values[:N]\n",
    "    most_similar_ratings = [ratings_matrix[user_id][to_id[x]] for x in most_similar_indexes]\n",
    "    predicted_rating = [x*y for x,y in zip(most_similar_corr,most_similar_ratings)]\n",
    "    dividend = sum(predicted_rating)\n",
    "    divisor = sum(most_similar_corr)\n",
    "\n",
    "    # There is a chance that the sum of the correlation of the most similiar movies is 0\n",
    "    # We then use the content based approach for prediction\n",
    "    if divisor == 0:\n",
    "        return content_based_user_movie(user_id,movie_id)\n",
    "        #return (movie_id,9)\n",
    "\n",
    "    else:\n",
    "        pred = np.around(dividend/divisor)\n",
    "        return (movie_id,pred)\n",
    "\n",
    "\n",
    "def collaborative_filtering(user_id,movies_rated,N):\n",
    "\n",
    "    \"\"\"Collaborative filter prediction for a given user\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int) : UserID\n",
    "    N (int) : Number of most correlated movies to use when predicting ranking for unknown data points\n",
    "    Returns:\n",
    "    [int]: Predicted ratings for movies not rated by the user\n",
    "\n",
    "   \"\"\"\n",
    "    movies_not_rated = ratings_matrix[user_id][ratings_matrix[user_id] == 0].index.values\n",
    "    movies_rated_i = [to_index[id] for id in movies_rated]\n",
    "\n",
    "    rows = similarity_matrix.iloc[movies_rated_i, :]\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for movie_id in movies_not_rated:\n",
    "        result.append(collabrative_user_movie(user_id,movie_id,rows,N))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "def content_based_user_movie(user_id, movie_id):\n",
    "\n",
    "    return (movie_id,9)\n",
    "    #return (movie_id,pred)\n",
    "\n",
    "\n",
    "def content_based(user_id):\n",
    "    \"\"\"Content-based rediction for a given user\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int) : UserID\n",
    "    Returns:\n",
    "    [(int,int)]: Predicted ratings for movies not rated by the user\n",
    "    \"\"\"\n",
    "\n",
    "    movies_not_rated = ratings_matrix[user_id][ratings_matrix[user_id] == 0].index.values\n",
    "\n",
    "    result = []\n",
    "\n",
    "    for movie_id in movies_not_rated:\n",
    "        result.append(content_based_user_movie(user_id,movie_id))\n",
    "\n",
    "    return result\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def get_hybrid_split(percentile):\n",
    "    user = []\n",
    "    rating_count = []\n",
    "    for user_id in ratings_matrix.columns.values:\n",
    "        movies_rated = len(ratings_matrix[user_id][ratings_matrix[user_id] != 0].index.values)\n",
    "        user.append(user_id)\n",
    "        rating_count.append(movies_rated)\n",
    "    return np.percentile(rating_count,percentile)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "# Main - Predictions\n",
    "\n",
    "def predict_user(user_id,split, collaborative_N):\n",
    "    \"\"\"Prediction for a given user\n",
    "\n",
    "    Parameters:\n",
    "    user_id (int) : UserID\n",
    "    hybrid_percentile:\n",
    "    collaborative_N: If the collaborative approach is to be used, N is the number of most similar movies to take into account\n",
    "\n",
    "    Returns: list of movies not rated bu user with a prediction\n",
    "    [(int,int)]: [(movie_id,predicted rating)]\n",
    "\n",
    "    \"\"\"\n",
    "    movies_rated = ratings_matrix[user_id][ratings_matrix[user_id] != 0].index.values\n",
    "\n",
    "    # If user is in the X% lowest number of movies rated we will use a content-based approach\n",
    "    if len(movies_rated) <= split:\n",
    "        print(\"Content-based prediction \" + str(user_id))\n",
    "        return (content_based(user_id, movies_rated))\n",
    "\n",
    "    else:\n",
    "        print(\"Collabrative filtering prediction for user \" + str(user_id))\n",
    "        return collaborative_filtering(user_id,movies_rated,collaborative_N)\n",
    "\n",
    "\n",
    "def predict(hybrid_split, N):\n",
    "    predictions = ratings_matrix.copy()\n",
    "    predictions = predictions.reset_index()\n",
    "\n",
    "    split = get_hybrid_split(hybrid_split)\n",
    "\n",
    "    # for every user, predict and put into dataframe\n",
    "    for user_id in [0,1]:#ratings_matrix.columns.values:\n",
    "        user_res = (predict_user(user_id,split,N))\n",
    "        for res in user_res:\n",
    "            movie_id = res[0]\n",
    "            pred = res[1]\n",
    "            predictions.iat[to_index[movie_id],user_id+1] = pred\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "    print(\"Done predicting values to predictions.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collabrative filtering prediction for user 0\n",
      "Collabrative filtering prediction for user 1\n",
      "BrukerID  FilmID    0    1    2    3    4    5    6    7    8  ...  6031  \\\n",
      "0              0  3.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "1              1  4.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "2              2  4.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "3              3  3.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "4              5  3.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "...          ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   \n",
      "3689        3948  3.0  3.0  0.0  0.0  4.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "3690        3949  2.0  4.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "3691        3950  3.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "3692        3951  1.0  4.0  0.0  0.0  4.0  0.0  4.0  0.0  0.0  ...   0.0   \n",
      "3693        3952  2.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   \n",
      "\n",
      "BrukerID  6032  6033  6034  6035  6036  6037  6038  6039  6040  \n",
      "0          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4          0.0   0.0   0.0   0.0   4.0   0.0   0.0   0.0   0.0  \n",
      "...        ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "3689       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3690       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3691       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3692       0.0   4.0   4.0   0.0   0.0   3.0   3.0   0.0   0.0  \n",
      "3693       0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[3694 rows x 6041 columns]\n",
      "Done predicting values to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "predict(15,2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}